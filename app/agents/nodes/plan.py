"""Plan node: Generate research plan and dimensions."""

from typing import Any

from pydantic import BaseModel, Field

from app.agents.state import AgentState
from app.core.logging import get_logger
from app.tools.llm import get_llm_client

logger = get_logger(__name__)


class EntityModelMapping(BaseModel):
    """å®ä½“ä¸ä»£è¡¨æ¨¡å‹çš„æ˜ å°„ã€‚"""
    entity: str = Field(..., description="å…¬å¸/ç»„ç»‡åç§°")
    representative_model: str = Field(..., description="ä»£è¡¨æ¨¡å‹åï¼ˆå¿…é¡»æ˜¯æ¨¡å‹åï¼Œä¸æ˜¯äº§å“åï¼‰")


class ResearchPlan(BaseModel):
    """æŠ•èµ„çº§ç ”ç©¶è®¡åˆ’ã€‚"""

    # Step -1: ç ”ç©¶æ¨¡å¼åˆ†ç±»ï¼ˆæœ€å…ˆåˆ¤æ–­ï¼Œä¸¥æ ¼ï¼‰
    research_mode: str = Field(
        ...,
        description="ç ”ç©¶æ¨¡å¼ï¼šA(å·²çŸ¥ç«å“å¯¹æ¯”) / B(å¸‚åœºåˆ†æ) / C(æ¦‚å¿µå‹/æ—©æœŸ)",
    )
    mode_confidence: float = Field(
        default=0.8,
        description="æ¨¡å¼åˆ¤æ–­ç½®ä¿¡åº¦ 0.0-1.0",
        ge=0.0,
        le=1.0,
    )
    mode_reason: str = Field(
        ...,
        description="æ¨¡å¼åˆ¤æ–­ç†ç”±ï¼ˆä¸€å¥è¯ï¼‰",
    )
    suggested_layer: str = Field(
        ...,
        description="å»ºè®®ç ”ç©¶å±‚çº§ï¼šApplication / Platform / Model / Network / Market",
    )
    risk_note: str = Field(
        default="",
        description="é£é™©æé†’ï¼ˆå¦‚æœè¯¥é—®é¢˜å®¹æ˜“å¤±è´¥æˆ–è¯¯è§£ï¼‰",
    )
    
    # Step 0: å¯è¡Œæ€§è¯„ä¼°
    feasibility_assessment: str = Field(
        ...,
        description="ç ”ç©¶å¯è¡Œæ€§è¯„ä¼°ï¼ˆä¸€å¥è¯è¯´æ˜æ˜¯å¦é€‚åˆåšç»“æ„åŒ–å¯¹æ¯”ï¼‰",
    )
    
    # Step 1: ç ”ç©¶å±‚çº§é”å®š
    research_level: str = Field(
        ...,
        description="ç ”ç©¶å±‚çº§ï¼šModel(åŸºç¡€æ¨¡å‹) / Platform(å¹³å°æ¡†æ¶) / Application(åº”ç”¨)",
    )
    
    # Step 1.5: å±‚çº§æ ¡æ­£ï¼ˆå¦‚æœéœ€è¦ï¼‰
    layer_correction_needed: bool = Field(
        default=False,
        description="æ˜¯å¦éœ€è¦å±‚çº§æ ¡æ­£ï¼ˆæœ‰æ•ˆå®ä½“<3æˆ–50%ä»¥ä¸Šæ— ä»£è¡¨å¯¹è±¡æ—¶ä¸ºTrueï¼‰",
    )
    corrected_level: str = Field(
        default="",
        description="æ ¡æ­£åçš„ç ”ç©¶å±‚çº§ï¼ˆå¦‚æœéœ€è¦æ ¡æ­£ï¼‰",
    )
    correction_reason: str = Field(
        default="",
        description="å±‚çº§æ ¡æ­£åŸå› è¯´æ˜",
    )
    
    # Step 2: ç ”ç©¶å¯¹è±¡å®šä¹‰
    entity_type: str = Field(
        ...,
        description="æ ¸å¿ƒç ”ç©¶å¯¹è±¡ç±»å‹",
    )
    entity_criteria: list[str] = Field(
        ...,
        description="å®ä½“å¿…é¡»æ»¡è¶³çš„æ¡ä»¶",
        min_length=1,
    )
    excluded_types: list[str] = Field(
        ...,
        description="å¿…é¡»æ’é™¤çš„å¯¹è±¡ç±»å‹",
        min_length=1,
    )
    
    # Step 3: å®ä½“-æ¨¡å‹æ˜ å°„ï¼ˆCanonical Entity Listï¼‰
    entity_model_mapping: list[EntityModelMapping] = Field(
        ...,
        description="å®ä½“ä¸ä»£è¡¨æ¨¡å‹çš„æ˜ å°„åˆ—è¡¨ï¼ˆ3-15ä¸ªï¼‰",
        min_length=3,
        max_length=15,
    )
    
    # Step 4: æœç´¢å…³é”®è¯
    search_keywords: list[str] = Field(
        ...,
        description="ç”¨äºæœç´¢çš„å…³é”®è¯",
        min_length=1,
    )


async def plan_node(state: AgentState) -> dict[str, Any]:
    """ç”ŸæˆæŠ•èµ„çº§ç ”ç©¶è®¡åˆ’ã€‚
    
    æ ¸å¿ƒåŸåˆ™ï¼šå…ˆåˆ¤æ–­å¯è¡Œæ€§ï¼Œå†é”å®šå®ä½“ï¼Œæœ€åä¸ºå®ä½“æ‰¾è¯æ®ã€‚
    """
    job_id = state["job_id"]
    query = state["query"]
    
    logger.info("plan_node_started", job_id=job_id, query=query)
    
    try:
        llm = get_llm_client()
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ª"ç ”ç©¶é—®é¢˜åˆ†ç±»å™¨ï¼ˆResearch Classifierï¼‰"ã€‚
ä½ çš„å”¯ä¸€ä»»åŠ¡æ˜¯åˆ¤æ–­ç”¨æˆ·é—®é¢˜åº”è¯¥ç”¨å“ªç§ç ”ç©¶æ¨¡å¼å¤„ç†ã€‚

## ç ”ç©¶é—®é¢˜
{query}

---

## Step -1: ç ”ç©¶æ¨¡å¼åˆ†ç±»ï¼ˆä¸¥æ ¼ï¼Œæœ€å…ˆåˆ¤æ–­ï¼‰

### Mode Aï¼šå·²çŸ¥ç«å“å¯¹æ¯”ï¼ˆKnown-Entity Comparisonï¼‰
ç‰¹å¾ï¼š
- æ˜ç¡®ç‚¹å â‰¥1 ä¸ªå…·ä½“äº§å“/å…¬å¸ï¼ˆå¦‚ Notionã€é£ä¹¦ã€iPhoneã€ChatGPTï¼‰
- æˆ–åŒ…å«å…³é”®è¯ï¼šç«å“ / å¯¹æ¯” / vs / æ›¿ä»£ / alternatives / ç±»ä¼¼

ç”¨æˆ·çœŸå®æ„å›¾ï¼šğŸ‘‰ "æˆ‘å·²ç»çŸ¥é“è¿™äº›ä¸œè¥¿ï¼Œè¯·ä½ ç›´æ¥å¸®æˆ‘å¯¹æ¯”"

è¡Œä¸ºè§„åˆ™ï¼ˆå¼ºåˆ¶ï¼‰ï¼š
- å®ä½“æ¥è‡ªè¡Œä¸šå¸¸è¯†ï¼Œä¸éœ€è¦éªŒè¯
- å®ä½“æ•°é‡å¿…é¡» â‰¥ 5
- æ ¸å¿ƒå¯¹æ¯”è¡¨å¿…é¡»åŒ…å« â‰¥ 3 ä¸ªå®ä½“
- âŒ ä¸å…è®¸è¾“å‡º"æ— æ³•ç”Ÿæˆç»“è®º"æˆ–"æå–å¤±è´¥"
- âœ… å¿…é¡»ç”Ÿæˆå¯¹æ¯”è¡¨

### Mode Bï¼šæˆç†Ÿ / åŠæˆç†Ÿå¸‚åœºåˆ†æï¼ˆMarket Analysisï¼‰
ç‰¹å¾ï¼š
- æè¿°ä¸€ä¸ªç›¸å¯¹æ¸…æ™°çš„å¸‚åœºæˆ–èµ›é“
- å®ä½“æ•°é‡æœ‰é™ä½†å¯æšä¸¾
- é€šå¸¸åŒ…å«ï¼šå¸‚åœº / è¡Œä¸š / æ ¼å±€ / ç°çŠ¶ / åˆ†æ / å¤§æ¨¡å‹

ç”¨æˆ·çœŸå®æ„å›¾ï¼šğŸ‘‰ "å¸®æˆ‘ç†è§£è¿™ä¸ªå¸‚åœºç°åœ¨æ˜¯ä»€ä¹ˆçŠ¶æ€"

è¡Œä¸ºè§„åˆ™ï¼š
- éœ€è¦åˆ—ä¸¾ä¸»è¦ç©å®¶
- å¯ä»¥ç”Ÿæˆå¯¹æ¯”è¡¨
- å…è®¸éƒ¨åˆ†å­—æ®µç¼ºå¤±

### Mode Cï¼šæ¦‚å¿µå‹ / æ—©æœŸå¸‚åœºåˆ¤æ–­ï¼ˆConcept / Early Marketï¼‰
ç‰¹å¾ï¼š
- æ¦‚å¿µæ¨¡ç³Šæˆ–é«˜åº¦å‰æ²¿
- å®ä½“ä¸æ¸…æ™°
- ç»å¸¸ç”±ä¸¤ä¸ªçƒ­ç‚¹è¯æ‹¼æ¥ï¼ˆå¦‚ Web3 + AIï¼‰

ç”¨æˆ·çœŸå®æ„å›¾ï¼šğŸ‘‰ "è¿™ä¸ªä¸œè¥¿åˆ°åº•æˆä¸æˆç«‹ï¼Ÿ"

è¡Œä¸ºè§„åˆ™ï¼š
- å…è®¸"ä¸é€‚åˆå¯¹æ¯”"ç»“è®º
- ä»¥åˆ¤æ–­ä¸ºä¸»ï¼Œè¡¨æ ¼ä¸ºè¾…

è¯·å¡«å†™ research_mode (A/B/C)ã€mode_confidence (0-1)ã€mode_reasonã€suggested_layerã€risk_noteã€‚

## Step 0: å¯è¡Œæ€§è¯„ä¼°
ç»™å‡ºä¸€å¥è¯è¯„ä¼°ï¼šæ˜¯å¦é€‚åˆåšç»“æ„åŒ–å¯¹æ¯”ç ”ç©¶ï¼Ÿ

## Step 1: ç ”ç©¶å±‚çº§é”å®š
æ˜ç¡®ç ”ç©¶å±‚çº§ï¼š
- Modelï¼ˆåŸºç¡€æ¨¡å‹ï¼‰
- Platformï¼ˆå¹³å°/æ¡†æ¶ï¼‰
- Applicationï¼ˆåº”ç”¨ï¼‰

âš ï¸ ä¸¥ç¦è·¨å±‚çº§æ··ç”¨ï¼

## Step 1.5: å±‚çº§æ ¡æ­£è§„åˆ™ï¼ˆå¼ºåˆ¶æ£€æŸ¥ï¼‰
å¦‚æœåœ¨æŒ‡å®šç ”ç©¶å±‚çº§ä¸‹ï¼š
- æœ‰æ•ˆå®ä½“ < 3 ä¸ª
- æˆ– 50% ä»¥ä¸Šå®ä½“æ— æ¸…æ™°ä»£è¡¨å¯¹è±¡

ä½ å¿…é¡»ï¼š
1. è®¾ç½® layer_correction_needed = true
2. åœ¨ corrected_level å¡«å†™ä¿¡æ¯å¯†åº¦æ›´é«˜çš„å±‚çº§
3. åœ¨ correction_reason è¯´æ˜åŸå› 

ç¤ºä¾‹ï¼š
"Web3 + AI åœ¨åŸºç¡€æ¨¡å‹å±‚å°šæœªå½¢æˆå¸‚åœºï¼Œå› æ­¤è½¬å‘ã€å»ä¸­å¿ƒåŒ–AIå¹³å°å±‚ã€‘è¿›è¡Œåˆ†æã€‚"

ç„¶ååŸºäºæ ¡æ­£åçš„å±‚çº§é‡æ–°ç”Ÿæˆå®ä½“åˆ—è¡¨ã€‚

## Step 2: ç ”ç©¶å¯¹è±¡å®šä¹‰
1. ç¡®å®šæ ¸å¿ƒç ”ç©¶å¯¹è±¡ç±»å‹
2. å®šä¹‰å®ä½“å¿…é¡»æ»¡è¶³çš„æ¡ä»¶
3. åˆ—å‡ºå¿…é¡»æ’é™¤çš„ç±»å‹ï¼ˆåº”ç”¨/æœç´¢/æµè§ˆå™¨/å·¥å…·ä¸èƒ½å……å½“æ¨¡å‹ï¼‰

## Step 3: å®ä½“-æ¨¡å‹æ˜ å°„ã€æ ¸å¿ƒã€‘
å¯¹äºæ¯ä¸ªå®ä½“ï¼Œè¿”å›ä¸€ä¸ªåŒ…å« entity å’Œ representative_model å­—æ®µçš„å¯¹è±¡ã€‚

æ ¼å¼è¦æ±‚ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š
entity_model_mapping å¿…é¡»æ˜¯å¯¹è±¡æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ï¼š
- "entity": "å…¬å¸/ç»„ç»‡åç§°"
- "representative_model": "ä»£è¡¨æ¨¡å‹å"

ç¤ºä¾‹ï¼š
[
  {{"entity": "OpenAI", "representative_model": "GPT-4o"}},
  {{"entity": "Anthropic", "representative_model": "Claude 3.5"}},
  {{"entity": "Google DeepMind", "representative_model": "Gemini 1.5"}}
]

å¦‚æœæ— æ³•æ˜ç¡®æ¨¡å‹åï¼Œrepresentative_model å¡« "æ— æ¸…æ™°ä»£è¡¨æ¨¡å‹"ã€‚
âŒ ç¦æ­¢ç”¨å­—ç¬¦ä¸²æ ¼å¼å¦‚ "OpenAI â†’ GPT-4o"ï¼å¿…é¡»ç”¨JSONå¯¹è±¡ï¼

## Step 4: æœç´¢å…³é”®è¯
å¿…é¡»åŒ…å«å®ä½“åç§° + è¯„æµ‹/å¯¹æ¯”/åˆ†æç­‰è¯

æ‰€æœ‰è¾“å‡ºå¿…é¡»ä½¿ç”¨ä¸­æ–‡ã€‚"""
        
        plan = await llm.generate_structured(
            prompt=prompt,
            response_model=ResearchPlan,
            system_prompt="ä½ æ˜¯æŠ•èµ„çº§ç ”ç©¶é¡¾é—®ã€‚é¦–å…ˆåˆ¤æ–­ç ”ç©¶å¯è¡Œæ€§ï¼Œå†é”å®šå®ä½“-æ¨¡å‹æ˜ å°„ã€‚å¦‚æœå¸‚åœºä¸æˆç†Ÿï¼Œå¿…é¡»æ˜ç¡®æŒ‡å‡ºã€‚ç”¨ä¸­æ–‡è¾“å‡ºã€‚",
        )
        
        plan_dict = plan.model_dump()
        
        # Extract entity names for backward compatibility
        plan_dict["canonical_entities"] = [m.entity for m in plan.entity_model_mapping]
        
        logger.info(
            "plan_node_completed",
            job_id=job_id,
            research_mode=plan.research_mode,
            entity_count=len(plan.entity_model_mapping),
            keywords_count=len(plan.search_keywords),
        )
        
        return {
            "plan": plan_dict,
            "step_count": state.get("step_count", 0) + 1,
            "progress": f"Mode {plan.research_mode}: {len(plan.entity_model_mapping)} entities",
        }
        
    except Exception as e:
        logger.error("plan_node_failed", job_id=job_id, error=str(e))
        errors = state.get("errors", [])
        errors.append({
            "node": "plan",
            "error": str(e),
            "error_type": type(e).__name__,
        })
        return {
            "errors": errors,
            "step_count": state.get("step_count", 0) + 1,
            "progress": "Plan generation failed",
        }
